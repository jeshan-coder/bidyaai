{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg6Fr3tpUVK7",
        "outputId": "99057ffd-a819-4e4b-d76c-54a737256b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhDVD7vlnTV7",
        "outputId": "b1a14cb6-65bf-4f4c-d5b7-7374a9e67b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m‚ö†Ô∏è  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `Jeshan` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Jeshan`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2csxkQlgUtg9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "REPO_ID = \"google/gemma-3n-E2B-it-litert-preview\"\n",
        "FILENAME = \"gemma-3n-E2B-it-int4.task\"\n",
        "# The destination folder in Google Colab\n",
        "DOWNLOAD_DIR = \"/content/\"\n",
        "\n",
        "print(f\"üöÄ Attempting to download: {FILENAME}\")\n",
        "print(f\"   Saving to: {DOWNLOAD_DIR}\")\n",
        "\n",
        "try:.\n",
        "    downloaded_file_path = hf_hub_download(\n",
        "        repo_id=REPO_ID,\n",
        "        filename=FILENAME,\n",
        "        repo_type=\"model\",\n",
        "        local_dir=DOWNLOAD_DIR,\n",
        "        local_dir_use_symlinks=False,\n",
        "    )\n",
        "\n",
        "    print(f\"\\n‚úÖ Download successful!\")\n",
        "    print(f\"   File saved to: {downloaded_file_path}\")\n",
        "\n",
        "except HfHubHTTPError as e:\n",
        "    print(f\"\\n‚ùå HTTP Error: {e}\")\n",
        "    print(\"\\n   Please ensure you have visited the model's page and accepted the license agreement:\")\n",
        "    print(f\"   https://huggingface.co/{REPO_ID}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "8e64fe85a4484c9fa9fee6267b33586f",
            "b3fdaa7aee9e438a8406c1e2fa452bf8",
            "1991954fb22e46a2a7b0e2435b3a2fca",
            "f0f576e046ec4f88b742066ca8cc9fbe",
            "d365229bcf6f4c6eb868b10b293d74af",
            "a3596de1d34a4052a1c5234e14f7803c",
            "e991e8cdd0724da694f530c1dbcbe9ce",
            "be309f64a7c24bb987da71c76ee01d7f",
            "4f8696e08b08480d8e9402fb8a06e210",
            "2edd5919b6334633a2aaca4d099714b2",
            "dec81946e25f47718fb678bea9704180"
          ]
        },
        "id": "3-p_9bXFRxW5",
        "outputId": "d5967d60-d068-4a79-ce3a-e57eb634baa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Attempting to download: gemma-3n-E2B-it-int4.task\n",
            "   Saving to: /content/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
            "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gemma-3n-E2B-it-int4.task:   0%|          | 0.00/3.14G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e64fe85a4484c9fa9fee6267b33586f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Download successful!\n",
            "   File saved to: /content/gemma-3n-E2B-it-int4.task\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# The full path to your file on Google Drive\n",
        "source_file_path = \"/content/drive/MyDrive/gemma3n-finetune-checkpoints/checkpoint-37/adapter_model.safetensors\"\n",
        "\n",
        "# The destination folder in Colab\n",
        "destination_folder = \"/content/\"\n",
        "\n",
        "print(f\"üöÄ Attempting to copy file from: {source_file_path}\")\n",
        "\n",
        "# --- Copy Logic ---\n",
        "try:\n",
        "    # Check if the source file actually exists before copying\n",
        "    if os.path.exists(source_file_path):\n",
        "        shutil.copy(source_file_path, destination_folder)\n",
        "        print(f\"\\n‚úÖ Success!\")\n",
        "        print(f\"   'adapter_model.safetensors' copied to: {destination_folder}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Error: Source file not found at the specified path.\")\n",
        "        print(\"   Please double-check the file path and that your drive is mounted correctly.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re9KI8HzS7Pz",
        "outputId": "45e9a9a2-daa7-4a61-a994-726d7a81a584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Attempting to copy file from: /content/drive/MyDrive/gemma3n-finetune-checkpoints/checkpoint-37/adapter_model.safetensors\n",
            "\n",
            "‚úÖ Success!\n",
            "   'adapter_model.safetensors' copied to: /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks.python.genai import converter"
      ],
      "metadata": {
        "id": "OWw_Ol_DTwWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "LORA_RANK = 32\n",
        "BASE_MODEL_FILENAME = \"gemma-3n-E2B-it-int4.task\"\n",
        "LORA_CHECKPOINT_FILENAME = \"adapter_model.safetensors\"\n",
        "OUTPUT_DIRECTORY = \"/content/\"\n",
        "CONVERTED_LORA_FILENAME = \"my_converted_lora.bin\""
      ],
      "metadata": {
        "id": "DQJf_5LkXj0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = converter.ConversionConfig(\n",
        "        # Required arguments\n",
        "        input_ckpt=os.path.join(OUTPUT_DIRECTORY, BASE_MODEL_FILENAME),\n",
        "        ckpt_format='task_file',\n",
        "        model_type='GEMMA_3N_IT',\n",
        "        output_dir=OUTPUT_DIRECTORY,\n",
        "        backend='gpu',\n",
        "\n",
        "        # LoRA specific parameters\n",
        "        lora_ckpt=os.path.join(OUTPUT_DIRECTORY, LORA_CHECKPOINT_FILENAME),\n",
        "        lora_rank=LORA_RANK,\n",
        "        lora_output_tflite_file=os.path.join(OUTPUT_DIRECTORY, CONVERTED_LORA_FILENAME),\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "XqmeKPgQTwdx",
        "outputId": "f4171ed6-4735-4de9-e49e-5d4d6989eeb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "LoRA is only applicable for the model_type: GEMMA_2B, GEMMA2_2B, PHI_2, but get model_type: GEMMA_3N_IT.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3358605191.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m config = converter.ConversionConfig(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;31m# Required arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0minput_ckpt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBASE_MODEL_FILENAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mckpt_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'task_file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GEMMA_3N_IT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# CORRECTED: Changed to uppercase to match docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mediapipe/tasks/python/genai/converter/llm_converter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_ckpt, ckpt_format, model_type, backend, output_dir, is_symmetric, attention_quant_bits, feedforward_quant_bits, embedding_quant_bits, combine_file_only, vocab_model_file, obfuscate, output_tflite_file, fp16_scale, lora_ckpt, lora_rank, lora_output_tflite_file, image_encoder_file, image_adapter_file, submodel_type, use_fake_weights)\u001b[0m\n\u001b[1;32m    124\u001b[0m       \u001b[0mlora_applicable_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'GEMMA_2B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GEMMA2_2B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PHI_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlora_applicable_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0;34m'LoRA is only applicable for the model_type:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;34mf' {\", \".join(lora_applicable_models)}, but get model_type:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: LoRA is only applicable for the model_type: GEMMA_2B, GEMMA2_2B, PHI_2, but get model_type: GEMMA_3N_IT."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concluded that no support for gemma 3n"
      ],
      "metadata": {
        "id": "QJlxstrOR-Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LORA_CHECKPOINT_PATH=\"/content/drive/MyDrive/gemma3n-finetune-checkpoints/checkpoint-37\""
      ],
      "metadata": {
        "id": "a_xi7USCbOYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# Load base Gemma 3n model and LoRA adapter\n",
        "base = AutoModel.from_pretrained(\"google/gemma-3n-e2b-it\")\n",
        "model = PeftModel.from_pretrained(base, LORA_CHECKPOINT_PATH)\n",
        "\n",
        "# Merge LoRA weights and save\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained(\"/tmp/merged_gemma3n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "2d0aacec1d494444bf6cbd5214008c8d",
            "f58b91a8dcc54f5b88584edf687cf9d0",
            "d3b64b893c0449a682ec48643b049846",
            "755ed2a99e0347308bb024dc15c6f7af",
            "b7aeb421b8f04eeda5b426446fc19410",
            "24ca5c245cf143d4adb1d09c7161bd1c",
            "db532df468524e0388bd5739d3fa6f13",
            "ccb4f95cd47e46aebf8051236fb7d09c",
            "20d2b3cd4ff34348b58de61c8f1969db",
            "7ea19090e0f542fda48b8021c11b989a",
            "1b0ff2716ee748be8116762499616c83"
          ]
        },
        "id": "YIIdAsoiTwgz",
        "outputId": "7198032b-421b-4f5d-8617-29eb1404dc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d0aacec1d494444bf6cbd5214008c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Gemma3nModel were not initialized from the model checkpoint at google/gemma-3n-e2b-it and are newly initialized: ['audio_tower.conformer.0.attention.attn.k_proj.weight', 'audio_tower.conformer.0.attention.attn.per_dim_scale', 'audio_tower.conformer.0.attention.attn.q_proj.weight', 'audio_tower.conformer.0.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.0.attention.attn.v_proj.weight', 'audio_tower.conformer.0.attention.post.weight', 'audio_tower.conformer.0.attention.post_norm.weight', 'audio_tower.conformer.0.attention.pre_attn_norm.weight', 'audio_tower.conformer.0.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.0.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.0.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.0.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.0.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.0.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.0.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.0.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.0.lconv1d.conv_norm.weight', 'audio_tower.conformer.0.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.0.lconv1d.linear_end.weight', 'audio_tower.conformer.0.lconv1d.linear_start.weight', 'audio_tower.conformer.0.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.0.norm.weight', 'audio_tower.conformer.1.attention.attn.k_proj.weight', 'audio_tower.conformer.1.attention.attn.per_dim_scale', 'audio_tower.conformer.1.attention.attn.q_proj.weight', 'audio_tower.conformer.1.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.1.attention.attn.v_proj.weight', 'audio_tower.conformer.1.attention.post.weight', 'audio_tower.conformer.1.attention.post_norm.weight', 'audio_tower.conformer.1.attention.pre_attn_norm.weight', 'audio_tower.conformer.1.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.1.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.1.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.1.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.1.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.1.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.1.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.1.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.1.lconv1d.conv_norm.weight', 'audio_tower.conformer.1.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.1.lconv1d.linear_end.weight', 'audio_tower.conformer.1.lconv1d.linear_start.weight', 'audio_tower.conformer.1.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.1.norm.weight', 'audio_tower.conformer.10.attention.attn.k_proj.weight', 'audio_tower.conformer.10.attention.attn.per_dim_scale', 'audio_tower.conformer.10.attention.attn.q_proj.weight', 'audio_tower.conformer.10.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.10.attention.attn.v_proj.weight', 'audio_tower.conformer.10.attention.post.weight', 'audio_tower.conformer.10.attention.post_norm.weight', 'audio_tower.conformer.10.attention.pre_attn_norm.weight', 'audio_tower.conformer.10.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.10.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.10.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.10.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.10.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.10.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.10.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.10.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.10.lconv1d.conv_norm.weight', 'audio_tower.conformer.10.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.10.lconv1d.linear_end.weight', 'audio_tower.conformer.10.lconv1d.linear_start.weight', 'audio_tower.conformer.10.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.10.norm.weight', 'audio_tower.conformer.11.attention.attn.k_proj.weight', 'audio_tower.conformer.11.attention.attn.per_dim_scale', 'audio_tower.conformer.11.attention.attn.q_proj.weight', 'audio_tower.conformer.11.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.11.attention.attn.v_proj.weight', 'audio_tower.conformer.11.attention.post.weight', 'audio_tower.conformer.11.attention.post_norm.weight', 'audio_tower.conformer.11.attention.pre_attn_norm.weight', 'audio_tower.conformer.11.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.11.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.11.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.11.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.11.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.11.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.11.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.11.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.11.lconv1d.conv_norm.weight', 'audio_tower.conformer.11.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.11.lconv1d.linear_end.weight', 'audio_tower.conformer.11.lconv1d.linear_start.weight', 'audio_tower.conformer.11.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.11.norm.weight', 'audio_tower.conformer.2.attention.attn.k_proj.weight', 'audio_tower.conformer.2.attention.attn.per_dim_scale', 'audio_tower.conformer.2.attention.attn.q_proj.weight', 'audio_tower.conformer.2.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.2.attention.attn.v_proj.weight', 'audio_tower.conformer.2.attention.post.weight', 'audio_tower.conformer.2.attention.post_norm.weight', 'audio_tower.conformer.2.attention.pre_attn_norm.weight', 'audio_tower.conformer.2.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.2.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.2.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.2.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.2.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.2.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.2.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.2.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.2.lconv1d.conv_norm.weight', 'audio_tower.conformer.2.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.2.lconv1d.linear_end.weight', 'audio_tower.conformer.2.lconv1d.linear_start.weight', 'audio_tower.conformer.2.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.2.norm.weight', 'audio_tower.conformer.3.attention.attn.k_proj.weight', 'audio_tower.conformer.3.attention.attn.per_dim_scale', 'audio_tower.conformer.3.attention.attn.q_proj.weight', 'audio_tower.conformer.3.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.3.attention.attn.v_proj.weight', 'audio_tower.conformer.3.attention.post.weight', 'audio_tower.conformer.3.attention.post_norm.weight', 'audio_tower.conformer.3.attention.pre_attn_norm.weight', 'audio_tower.conformer.3.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.3.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.3.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.3.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.3.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.3.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.3.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.3.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.3.lconv1d.conv_norm.weight', 'audio_tower.conformer.3.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.3.lconv1d.linear_end.weight', 'audio_tower.conformer.3.lconv1d.linear_start.weight', 'audio_tower.conformer.3.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.3.norm.weight', 'audio_tower.conformer.4.attention.attn.k_proj.weight', 'audio_tower.conformer.4.attention.attn.per_dim_scale', 'audio_tower.conformer.4.attention.attn.q_proj.weight', 'audio_tower.conformer.4.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.4.attention.attn.v_proj.weight', 'audio_tower.conformer.4.attention.post.weight', 'audio_tower.conformer.4.attention.post_norm.weight', 'audio_tower.conformer.4.attention.pre_attn_norm.weight', 'audio_tower.conformer.4.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.4.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.4.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.4.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.4.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.4.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.4.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.4.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.4.lconv1d.conv_norm.weight', 'audio_tower.conformer.4.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.4.lconv1d.linear_end.weight', 'audio_tower.conformer.4.lconv1d.linear_start.weight', 'audio_tower.conformer.4.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.4.norm.weight', 'audio_tower.conformer.5.attention.attn.k_proj.weight', 'audio_tower.conformer.5.attention.attn.per_dim_scale', 'audio_tower.conformer.5.attention.attn.q_proj.weight', 'audio_tower.conformer.5.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.5.attention.attn.v_proj.weight', 'audio_tower.conformer.5.attention.post.weight', 'audio_tower.conformer.5.attention.post_norm.weight', 'audio_tower.conformer.5.attention.pre_attn_norm.weight', 'audio_tower.conformer.5.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.5.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.5.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.5.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.5.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.5.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.5.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.5.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.5.lconv1d.conv_norm.weight', 'audio_tower.conformer.5.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.5.lconv1d.linear_end.weight', 'audio_tower.conformer.5.lconv1d.linear_start.weight', 'audio_tower.conformer.5.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.5.norm.weight', 'audio_tower.conformer.6.attention.attn.k_proj.weight', 'audio_tower.conformer.6.attention.attn.per_dim_scale', 'audio_tower.conformer.6.attention.attn.q_proj.weight', 'audio_tower.conformer.6.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.6.attention.attn.v_proj.weight', 'audio_tower.conformer.6.attention.post.weight', 'audio_tower.conformer.6.attention.post_norm.weight', 'audio_tower.conformer.6.attention.pre_attn_norm.weight', 'audio_tower.conformer.6.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.6.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.6.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.6.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.6.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.6.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.6.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.6.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.6.lconv1d.conv_norm.weight', 'audio_tower.conformer.6.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.6.lconv1d.linear_end.weight', 'audio_tower.conformer.6.lconv1d.linear_start.weight', 'audio_tower.conformer.6.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.6.norm.weight', 'audio_tower.conformer.7.attention.attn.k_proj.weight', 'audio_tower.conformer.7.attention.attn.per_dim_scale', 'audio_tower.conformer.7.attention.attn.q_proj.weight', 'audio_tower.conformer.7.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.7.attention.attn.v_proj.weight', 'audio_tower.conformer.7.attention.post.weight', 'audio_tower.conformer.7.attention.post_norm.weight', 'audio_tower.conformer.7.attention.pre_attn_norm.weight', 'audio_tower.conformer.7.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.7.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.7.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.7.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.7.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.7.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.7.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.7.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.7.lconv1d.conv_norm.weight', 'audio_tower.conformer.7.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.7.lconv1d.linear_end.weight', 'audio_tower.conformer.7.lconv1d.linear_start.weight', 'audio_tower.conformer.7.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.7.norm.weight', 'audio_tower.conformer.8.attention.attn.k_proj.weight', 'audio_tower.conformer.8.attention.attn.per_dim_scale', 'audio_tower.conformer.8.attention.attn.q_proj.weight', 'audio_tower.conformer.8.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.8.attention.attn.v_proj.weight', 'audio_tower.conformer.8.attention.post.weight', 'audio_tower.conformer.8.attention.post_norm.weight', 'audio_tower.conformer.8.attention.pre_attn_norm.weight', 'audio_tower.conformer.8.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.8.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.8.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.8.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.8.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.8.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.8.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.8.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.8.lconv1d.conv_norm.weight', 'audio_tower.conformer.8.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.8.lconv1d.linear_end.weight', 'audio_tower.conformer.8.lconv1d.linear_start.weight', 'audio_tower.conformer.8.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.8.norm.weight', 'audio_tower.conformer.9.attention.attn.k_proj.weight', 'audio_tower.conformer.9.attention.attn.per_dim_scale', 'audio_tower.conformer.9.attention.attn.q_proj.weight', 'audio_tower.conformer.9.attention.attn.relative_position_embedding.pos_proj.weight', 'audio_tower.conformer.9.attention.attn.v_proj.weight', 'audio_tower.conformer.9.attention.post.weight', 'audio_tower.conformer.9.attention.post_norm.weight', 'audio_tower.conformer.9.attention.pre_attn_norm.weight', 'audio_tower.conformer.9.ffw_layer_end.ffw_layer_1.weight', 'audio_tower.conformer.9.ffw_layer_end.ffw_layer_2.weight', 'audio_tower.conformer.9.ffw_layer_end.post_layer_norm.weight', 'audio_tower.conformer.9.ffw_layer_end.pre_layer_norm.weight', 'audio_tower.conformer.9.ffw_layer_start.ffw_layer_1.weight', 'audio_tower.conformer.9.ffw_layer_start.ffw_layer_2.weight', 'audio_tower.conformer.9.ffw_layer_start.post_layer_norm.weight', 'audio_tower.conformer.9.ffw_layer_start.pre_layer_norm.weight', 'audio_tower.conformer.9.lconv1d.conv_norm.weight', 'audio_tower.conformer.9.lconv1d.depthwise_conv1d.weight', 'audio_tower.conformer.9.lconv1d.linear_end.weight', 'audio_tower.conformer.9.lconv1d.linear_start.weight', 'audio_tower.conformer.9.lconv1d.pre_layer_norm.weight', 'audio_tower.conformer.9.norm.weight', 'audio_tower.subsample_conv_projection.conv_0.conv.weight', 'audio_tower.subsample_conv_projection.conv_0.norm.weight', 'audio_tower.subsample_conv_projection.conv_1.conv.weight', 'audio_tower.subsample_conv_projection.conv_1.norm.weight', 'audio_tower.subsample_conv_projection.input_proj_linear.weight', 'embed_audio.embedding.weight', 'embed_audio.embedding_projection.weight', 'embed_audio.hard_embedding_norm.weight', 'embed_audio.soft_embedding_norm.weight', 'embed_vision.embedding.weight', 'embed_vision.embedding_projection.weight', 'embed_vision.hard_embedding_norm.weight', 'embed_vision.soft_embedding_norm.weight', 'language_model.altup_projections.0.weight', 'language_model.altup_projections.1.weight', 'language_model.altup_projections.2.weight', 'language_model.altup_unembed_projections.0.weight', 'language_model.altup_unembed_projections.1.weight', 'language_model.altup_unembed_projections.2.weight', 'language_model.embed_tokens.weight', 'language_model.embed_tokens_per_layer.weight', 'language_model.layers.0.altup.correct_output_scale', 'language_model.layers.0.altup.correction_coefs.weight', 'language_model.layers.0.altup.modality_router.weight', 'language_model.layers.0.altup.prediction_coefs.weight', 'language_model.layers.0.altup.router_norm.weight', 'language_model.layers.0.input_layernorm.weight', 'language_model.layers.0.laurel.linear_left.weight', 'language_model.layers.0.laurel.linear_right.weight', 'language_model.layers.0.laurel.post_laurel_norm.weight', 'language_model.layers.0.mlp.down_proj.weight', 'language_model.layers.0.mlp.gate_proj.weight', 'language_model.layers.0.mlp.up_proj.weight', 'language_model.layers.0.per_layer_input_gate.weight', 'language_model.layers.0.per_layer_projection.weight', 'language_model.layers.0.post_attention_layernorm.weight', 'language_model.layers.0.post_feedforward_layernorm.weight', 'language_model.layers.0.post_per_layer_input_norm.weight', 'language_model.layers.0.pre_feedforward_layernorm.weight', 'language_model.layers.0.self_attn.k_norm.weight', 'language_model.layers.0.self_attn.k_proj.weight', 'language_model.layers.0.self_attn.o_proj.weight', 'language_model.layers.0.self_attn.q_norm.weight', 'language_model.layers.0.self_attn.q_proj.weight', 'language_model.layers.0.self_attn.v_proj.weight', 'language_model.layers.1.altup.correct_output_scale', 'language_model.layers.1.altup.correction_coefs.weight', 'language_model.layers.1.altup.modality_router.weight', 'language_model.layers.1.altup.prediction_coefs.weight', 'language_model.layers.1.altup.router_norm.weight', 'language_model.layers.1.input_layernorm.weight', 'language_model.layers.1.laurel.linear_left.weight', 'language_model.layers.1.laurel.linear_right.weight', 'language_model.layers.1.laurel.post_laurel_norm.weight', 'language_model.layers.1.mlp.down_proj.weight', 'language_model.layers.1.mlp.gate_proj.weight', 'language_model.layers.1.mlp.up_proj.weight', 'language_model.layers.1.per_layer_input_gate.weight', 'language_model.layers.1.per_layer_projection.weight', 'language_model.layers.1.post_attention_layernorm.weight', 'language_model.layers.1.post_feedforward_layernorm.weight', 'language_model.layers.1.post_per_layer_input_norm.weight', 'language_model.layers.1.pre_feedforward_layernorm.weight', 'language_model.layers.1.self_attn.k_norm.weight', 'language_model.layers.1.self_attn.k_proj.weight', 'language_model.layers.1.self_attn.o_proj.weight', 'language_model.layers.1.self_attn.q_norm.weight', 'language_model.layers.1.self_attn.q_proj.weight', 'language_model.layers.1.self_attn.v_proj.weight', 'language_model.layers.10.altup.correct_output_scale', 'language_model.layers.10.altup.correction_coefs.weight', 'language_model.layers.10.altup.modality_router.weight', 'language_model.layers.10.altup.prediction_coefs.weight', 'language_model.layers.10.altup.router_norm.weight', 'language_model.layers.10.input_layernorm.weight', 'language_model.layers.10.laurel.linear_left.weight', 'language_model.layers.10.laurel.linear_right.weight', 'language_model.layers.10.laurel.post_laurel_norm.weight', 'language_model.layers.10.mlp.down_proj.weight', 'language_model.layers.10.mlp.gate_proj.weight', 'language_model.layers.10.mlp.up_proj.weight', 'language_model.layers.10.per_layer_input_gate.weight', 'language_model.layers.10.per_layer_projection.weight', 'language_model.layers.10.post_attention_layernorm.weight', 'language_model.layers.10.post_feedforward_layernorm.weight', 'language_model.layers.10.post_per_layer_input_norm.weight', 'language_model.layers.10.pre_feedforward_layernorm.weight', 'language_model.layers.10.self_attn.k_norm.weight', 'language_model.layers.10.self_attn.k_proj.weight', 'language_model.layers.10.self_attn.o_proj.weight', 'language_model.layers.10.self_attn.q_norm.weight', 'language_model.layers.10.self_attn.q_proj.weight', 'language_model.layers.10.self_attn.v_proj.weight', 'language_model.layers.11.altup.correct_output_scale', 'language_model.layers.11.altup.correction_coefs.weight', 'language_model.layers.11.altup.modality_router.weight', 'language_model.layers.11.altup.prediction_coefs.weight', 'language_model.layers.11.altup.router_norm.weight', 'language_model.layers.11.input_layernorm.weight', 'language_model.layers.11.laurel.linear_left.weight', 'language_model.layers.11.laurel.linear_right.weight', 'language_model.layers.11.laurel.post_laurel_norm.weight', 'language_model.layers.11.mlp.down_proj.weight', 'language_model.layers.11.mlp.gate_proj.weight', 'language_model.layers.11.mlp.up_proj.weight', 'language_model.layers.11.per_layer_input_gate.weight', 'language_model.layers.11.per_layer_projection.weight', 'language_model.layers.11.post_attention_layernorm.weight', 'language_model.layers.11.post_feedforward_layernorm.weight', 'language_model.layers.11.post_per_layer_input_norm.weight', 'language_model.layers.11.pre_feedforward_layernorm.weight', 'language_model.layers.11.self_attn.k_norm.weight', 'language_model.layers.11.self_attn.k_proj.weight', 'language_model.layers.11.self_attn.o_proj.weight', 'language_model.layers.11.self_attn.q_norm.weight', 'language_model.layers.11.self_attn.q_proj.weight', 'language_model.layers.11.self_attn.v_proj.weight', 'language_model.layers.12.altup.correct_output_scale', 'language_model.layers.12.altup.correction_coefs.weight', 'language_model.layers.12.altup.modality_router.weight', 'language_model.layers.12.altup.prediction_coefs.weight', 'language_model.layers.12.altup.router_norm.weight', 'language_model.layers.12.input_layernorm.weight', 'language_model.layers.12.laurel.linear_left.weight', 'language_model.layers.12.laurel.linear_right.weight', 'language_model.layers.12.laurel.post_laurel_norm.weight', 'language_model.layers.12.mlp.down_proj.weight', 'language_model.layers.12.mlp.gate_proj.weight', 'language_model.layers.12.mlp.up_proj.weight', 'language_model.layers.12.per_layer_input_gate.weight', 'language_model.layers.12.per_layer_projection.weight', 'language_model.layers.12.post_attention_layernorm.weight', 'language_model.layers.12.post_feedforward_layernorm.weight', 'language_model.layers.12.post_per_layer_input_norm.weight', 'language_model.layers.12.pre_feedforward_layernorm.weight', 'language_model.layers.12.self_attn.k_norm.weight', 'language_model.layers.12.self_attn.k_proj.weight', 'language_model.layers.12.self_attn.o_proj.weight', 'language_model.layers.12.self_attn.q_norm.weight', 'language_model.layers.12.self_attn.q_proj.weight', 'language_model.layers.12.self_attn.v_proj.weight', 'language_model.layers.13.altup.correct_output_scale', 'language_model.layers.13.altup.correction_coefs.weight', 'language_model.layers.13.altup.modality_router.weight', 'language_model.layers.13.altup.prediction_coefs.weight', 'language_model.layers.13.altup.router_norm.weight', 'language_model.layers.13.input_layernorm.weight', 'language_model.layers.13.laurel.linear_left.weight', 'language_model.layers.13.laurel.linear_right.weight', 'language_model.layers.13.laurel.post_laurel_norm.weight', 'language_model.layers.13.mlp.down_proj.weight', 'language_model.layers.13.mlp.gate_proj.weight', 'language_model.layers.13.mlp.up_proj.weight', 'language_model.layers.13.per_layer_input_gate.weight', 'language_model.layers.13.per_layer_projection.weight', 'language_model.layers.13.post_attention_layernorm.weight', 'language_model.layers.13.post_feedforward_layernorm.weight', 'language_model.layers.13.post_per_layer_input_norm.weight', 'language_model.layers.13.pre_feedforward_layernorm.weight', 'language_model.layers.13.self_attn.k_norm.weight', 'language_model.layers.13.self_attn.k_proj.weight', 'language_model.layers.13.self_attn.o_proj.weight', 'language_model.layers.13.self_attn.q_norm.weight', 'language_model.layers.13.self_attn.q_proj.weight', 'language_model.layers.13.self_attn.v_proj.weight', 'language_model.layers.14.altup.correct_output_scale', 'language_model.layers.14.altup.correction_coefs.weight', 'language_model.layers.14.altup.modality_router.weight', 'language_model.layers.14.altup.prediction_coefs.weight', 'language_model.layers.14.altup.router_norm.weight', 'language_model.layers.14.input_layernorm.weight', 'language_model.layers.14.laurel.linear_left.weight', 'language_model.layers.14.laurel.linear_right.weight', 'language_model.layers.14.laurel.post_laurel_norm.weight', 'language_model.layers.14.mlp.down_proj.weight', 'language_model.layers.14.mlp.gate_proj.weight', 'language_model.layers.14.mlp.up_proj.weight', 'language_model.layers.14.per_layer_input_gate.weight', 'language_model.layers.14.per_layer_projection.weight', 'language_model.layers.14.post_attention_layernorm.weight', 'language_model.layers.14.post_feedforward_layernorm.weight', 'language_model.layers.14.post_per_layer_input_norm.weight', 'language_model.layers.14.pre_feedforward_layernorm.weight', 'language_model.layers.14.self_attn.k_norm.weight', 'language_model.layers.14.self_attn.k_proj.weight', 'language_model.layers.14.self_attn.o_proj.weight', 'language_model.layers.14.self_attn.q_norm.weight', 'language_model.layers.14.self_attn.q_proj.weight', 'language_model.layers.14.self_attn.v_proj.weight', 'language_model.layers.15.altup.correct_output_scale', 'language_model.layers.15.altup.correction_coefs.weight', 'language_model.layers.15.altup.modality_router.weight', 'language_model.layers.15.altup.prediction_coefs.weight', 'language_model.layers.15.altup.router_norm.weight', 'language_model.layers.15.input_layernorm.weight', 'language_model.layers.15.laurel.linear_left.weight', 'language_model.layers.15.laurel.linear_right.weight', 'language_model.layers.15.laurel.post_laurel_norm.weight', 'language_model.layers.15.mlp.down_proj.weight', 'language_model.layers.15.mlp.gate_proj.weight', 'language_model.layers.15.mlp.up_proj.weight', 'language_model.layers.15.per_layer_input_gate.weight', 'language_model.layers.15.per_layer_projection.weight', 'language_model.layers.15.post_attention_layernorm.weight', 'language_model.layers.15.post_feedforward_layernorm.weight', 'language_model.layers.15.post_per_layer_input_norm.weight', 'language_model.layers.15.pre_feedforward_layernorm.weight', 'language_model.layers.15.self_attn.k_norm.weight', 'language_model.layers.15.self_attn.k_proj.weight', 'language_model.layers.15.self_attn.o_proj.weight', 'language_model.layers.15.self_attn.q_norm.weight', 'language_model.layers.15.self_attn.q_proj.weight', 'language_model.layers.15.self_attn.v_proj.weight', 'language_model.layers.16.altup.correct_output_scale', 'language_model.layers.16.altup.correction_coefs.weight', 'language_model.layers.16.altup.modality_router.weight', 'language_model.layers.16.altup.prediction_coefs.weight', 'language_model.layers.16.altup.router_norm.weight', 'language_model.layers.16.input_layernorm.weight', 'language_model.layers.16.laurel.linear_left.weight', 'language_model.layers.16.laurel.linear_right.weight', 'language_model.layers.16.laurel.post_laurel_norm.weight', 'language_model.layers.16.mlp.down_proj.weight', 'language_model.layers.16.mlp.gate_proj.weight', 'language_model.layers.16.mlp.up_proj.weight', 'language_model.layers.16.per_layer_input_gate.weight', 'language_model.layers.16.per_layer_projection.weight', 'language_model.layers.16.post_attention_layernorm.weight', 'language_model.layers.16.post_feedforward_layernorm.weight', 'language_model.layers.16.post_per_layer_input_norm.weight', 'language_model.layers.16.pre_feedforward_layernorm.weight', 'language_model.layers.16.self_attn.k_norm.weight', 'language_model.layers.16.self_attn.k_proj.weight', 'language_model.layers.16.self_attn.o_proj.weight', 'language_model.layers.16.self_attn.q_norm.weight', 'language_model.layers.16.self_attn.q_proj.weight', 'language_model.layers.16.self_attn.v_proj.weight', 'language_model.layers.17.altup.correct_output_scale', 'language_model.layers.17.altup.correction_coefs.weight', 'language_model.layers.17.altup.modality_router.weight', 'language_model.layers.17.altup.prediction_coefs.weight', 'language_model.layers.17.altup.router_norm.weight', 'language_model.layers.17.input_layernorm.weight', 'language_model.layers.17.laurel.linear_left.weight', 'language_model.layers.17.laurel.linear_right.weight', 'language_model.layers.17.laurel.post_laurel_norm.weight', 'language_model.layers.17.mlp.down_proj.weight', 'language_model.layers.17.mlp.gate_proj.weight', 'language_model.layers.17.mlp.up_proj.weight', 'language_model.layers.17.per_layer_input_gate.weight', 'language_model.layers.17.per_layer_projection.weight', 'language_model.layers.17.post_attention_layernorm.weight', 'language_model.layers.17.post_feedforward_layernorm.weight', 'language_model.layers.17.post_per_layer_input_norm.weight', 'language_model.layers.17.pre_feedforward_layernorm.weight', 'language_model.layers.17.self_attn.k_norm.weight', 'language_model.layers.17.self_attn.k_proj.weight', 'language_model.layers.17.self_attn.o_proj.weight', 'language_model.layers.17.self_attn.q_norm.weight', 'language_model.layers.17.self_attn.q_proj.weight', 'language_model.layers.17.self_attn.v_proj.weight', 'language_model.layers.18.altup.correct_output_scale', 'language_model.layers.18.altup.correction_coefs.weight', 'language_model.layers.18.altup.modality_router.weight', 'language_model.layers.18.altup.prediction_coefs.weight', 'language_model.layers.18.altup.router_norm.weight', 'language_model.layers.18.input_layernorm.weight', 'language_model.layers.18.laurel.linear_left.weight', 'language_model.layers.18.laurel.linear_right.weight', 'language_model.layers.18.laurel.post_laurel_norm.weight', 'language_model.layers.18.mlp.down_proj.weight', 'language_model.layers.18.mlp.gate_proj.weight', 'language_model.layers.18.mlp.up_proj.weight', 'language_model.layers.18.per_layer_input_gate.weight', 'language_model.layers.18.per_layer_projection.weight', 'language_model.layers.18.post_attention_layernorm.weight', 'language_model.layers.18.post_feedforward_layernorm.weight', 'language_model.layers.18.post_per_layer_input_norm.weight', 'language_model.layers.18.pre_feedforward_layernorm.weight', 'language_model.layers.18.self_attn.k_norm.weight', 'language_model.layers.18.self_attn.k_proj.weight', 'language_model.layers.18.self_attn.o_proj.weight', 'language_model.layers.18.self_attn.q_norm.weight', 'language_model.layers.18.self_attn.q_proj.weight', 'language_model.layers.18.self_attn.v_proj.weight', 'language_model.layers.19.altup.correct_output_scale', 'language_model.layers.19.altup.correction_coefs.weight', 'language_model.layers.19.altup.modality_router.weight', 'language_model.layers.19.altup.prediction_coefs.weight', 'language_model.layers.19.altup.router_norm.weight', 'language_model.layers.19.input_layernorm.weight', 'language_model.layers.19.laurel.linear_left.weight', 'language_model.layers.19.laurel.linear_right.weight', 'language_model.layers.19.laurel.post_laurel_norm.weight', 'language_model.layers.19.mlp.down_proj.weight', 'language_model.layers.19.mlp.gate_proj.weight', 'language_model.layers.19.mlp.up_proj.weight', 'language_model.layers.19.per_layer_input_gate.weight', 'language_model.layers.19.per_layer_projection.weight', 'language_model.layers.19.post_attention_layernorm.weight', 'language_model.layers.19.post_feedforward_layernorm.weight', 'language_model.layers.19.post_per_layer_input_norm.weight', 'language_model.layers.19.pre_feedforward_layernorm.weight', 'language_model.layers.19.self_attn.k_norm.weight', 'language_model.layers.19.self_attn.k_proj.weight', 'language_model.layers.19.self_attn.o_proj.weight', 'language_model.layers.19.self_attn.q_norm.weight', 'language_model.layers.19.self_attn.q_proj.weight', 'language_model.layers.19.self_attn.v_proj.weight', 'language_model.layers.2.altup.correct_output_scale', 'language_model.layers.2.altup.correction_coefs.weight', 'language_model.layers.2.altup.modality_router.weight', 'language_model.layers.2.altup.prediction_coefs.weight', 'language_model.layers.2.altup.router_norm.weight', 'language_model.layers.2.input_layernorm.weight', 'language_model.layers.2.laurel.linear_left.weight', 'language_model.layers.2.laurel.linear_right.weight', 'language_model.layers.2.laurel.post_laurel_norm.weight', 'language_model.layers.2.mlp.down_proj.weight', 'language_model.layers.2.mlp.gate_proj.weight', 'language_model.layers.2.mlp.up_proj.weight', 'language_model.layers.2.per_layer_input_gate.weight', 'language_model.layers.2.per_layer_projection.weight', 'language_model.layers.2.post_attention_layernorm.weight', 'language_model.layers.2.post_feedforward_layernorm.weight', 'language_model.layers.2.post_per_layer_input_norm.weight', 'language_model.layers.2.pre_feedforward_layernorm.weight', 'language_model.layers.2.self_attn.k_norm.weight', 'language_model.layers.2.self_attn.k_proj.weight', 'language_model.layers.2.self_attn.o_proj.weight', 'language_model.layers.2.self_attn.q_norm.weight', 'language_model.layers.2.self_attn.q_proj.weight', 'language_model.layers.2.self_attn.v_proj.weight', 'language_model.layers.20.altup.correct_output_scale', 'language_model.layers.20.altup.correction_coefs.weight', 'language_model.layers.20.altup.modality_router.weight', 'language_model.layers.20.altup.prediction_coefs.weight', 'language_model.layers.20.altup.router_norm.weight', 'language_model.layers.20.input_layernorm.weight', 'language_model.layers.20.laurel.linear_left.weight', 'language_model.layers.20.laurel.linear_right.weight', 'language_model.layers.20.laurel.post_laurel_norm.weight', 'language_model.layers.20.mlp.down_proj.weight', 'language_model.layers.20.mlp.gate_proj.weight', 'language_model.layers.20.mlp.up_proj.weight', 'language_model.layers.20.per_layer_input_gate.weight', 'language_model.layers.20.per_layer_projection.weight', 'language_model.layers.20.post_attention_layernorm.weight', 'language_model.layers.20.post_feedforward_layernorm.weight', 'language_model.layers.20.post_per_layer_input_norm.weight', 'language_model.layers.20.pre_feedforward_layernorm.weight', 'language_model.layers.20.self_attn.k_norm.weight', 'language_model.layers.20.self_attn.k_proj.weight', 'language_model.layers.20.self_attn.o_proj.weight', 'language_model.layers.20.self_attn.q_norm.weight', 'language_model.layers.20.self_attn.q_proj.weight', 'language_model.layers.20.self_attn.v_proj.weight', 'language_model.layers.21.altup.correct_output_scale', 'language_model.layers.21.altup.correction_coefs.weight', 'language_model.layers.21.altup.modality_router.weight', 'language_model.layers.21.altup.prediction_coefs.weight', 'language_model.layers.21.altup.router_norm.weight', 'language_model.layers.21.input_layernorm.weight', 'language_model.layers.21.laurel.linear_left.weight', 'language_model.layers.21.laurel.linear_right.weight', 'language_model.layers.21.laurel.post_laurel_norm.weight', 'language_model.layers.21.mlp.down_proj.weight', 'language_model.layers.21.mlp.gate_proj.weight', 'language_model.layers.21.mlp.up_proj.weight', 'language_model.layers.21.per_layer_input_gate.weight', 'language_model.layers.21.per_layer_projection.weight', 'language_model.layers.21.post_attention_layernorm.weight', 'language_model.layers.21.post_feedforward_layernorm.weight', 'language_model.layers.21.post_per_layer_input_norm.weight', 'language_model.layers.21.pre_feedforward_layernorm.weight', 'language_model.layers.21.self_attn.k_norm.weight', 'language_model.layers.21.self_attn.k_proj.weight', 'language_model.layers.21.self_attn.o_proj.weight', 'language_model.layers.21.self_attn.q_norm.weight', 'language_model.layers.21.self_attn.q_proj.weight', 'language_model.layers.21.self_attn.v_proj.weight', 'language_model.layers.22.altup.correct_output_scale', 'language_model.layers.22.altup.correction_coefs.weight', 'language_model.layers.22.altup.modality_router.weight', 'language_model.layers.22.altup.prediction_coefs.weight', 'language_model.layers.22.altup.router_norm.weight', 'language_model.layers.22.input_layernorm.weight', 'language_model.layers.22.laurel.linear_left.weight', 'language_model.layers.22.laurel.linear_right.weight', 'language_model.layers.22.laurel.post_laurel_norm.weight', 'language_model.layers.22.mlp.down_proj.weight', 'language_model.layers.22.mlp.gate_proj.weight', 'language_model.layers.22.mlp.up_proj.weight', 'language_model.layers.22.per_layer_input_gate.weight', 'language_model.layers.22.per_layer_projection.weight', 'language_model.layers.22.post_attention_layernorm.weight', 'language_model.layers.22.post_feedforward_layernorm.weight', 'language_model.layers.22.post_per_layer_input_norm.weight', 'language_model.layers.22.pre_feedforward_layernorm.weight', 'language_model.layers.22.self_attn.k_norm.weight', 'language_model.layers.22.self_attn.k_proj.weight', 'language_model.layers.22.self_attn.o_proj.weight', 'language_model.layers.22.self_attn.q_norm.weight', 'language_model.layers.22.self_attn.q_proj.weight', 'language_model.layers.22.self_attn.v_proj.weight', 'language_model.layers.23.altup.correct_output_scale', 'language_model.layers.23.altup.correction_coefs.weight', 'language_model.layers.23.altup.modality_router.weight', 'language_model.layers.23.altup.prediction_coefs.weight', 'language_model.layers.23.altup.router_norm.weight', 'language_model.layers.23.input_layernorm.weight', 'language_model.layers.23.laurel.linear_left.weight', 'language_model.layers.23.laurel.linear_right.weight', 'language_model.layers.23.laurel.post_laurel_norm.weight', 'language_model.layers.23.mlp.down_proj.weight', 'language_model.layers.23.mlp.gate_proj.weight', 'language_model.layers.23.mlp.up_proj.weight', 'language_model.layers.23.per_layer_input_gate.weight', 'language_model.layers.23.per_layer_projection.weight', 'language_model.layers.23.post_attention_layernorm.weight', 'language_model.layers.23.post_feedforward_layernorm.weight', 'language_model.layers.23.post_per_layer_input_norm.weight', 'language_model.layers.23.pre_feedforward_layernorm.weight', 'language_model.layers.23.self_attn.k_norm.weight', 'language_model.layers.23.self_attn.k_proj.weight', 'language_model.layers.23.self_attn.o_proj.weight', 'language_model.layers.23.self_attn.q_norm.weight', 'language_model.layers.23.self_attn.q_proj.weight', 'language_model.layers.23.self_attn.v_proj.weight', 'language_model.layers.24.altup.correct_output_scale', 'language_model.layers.24.altup.correction_coefs.weight', 'language_model.layers.24.altup.modality_router.weight', 'language_model.layers.24.altup.prediction_coefs.weight', 'language_model.layers.24.altup.router_norm.weight', 'language_model.layers.24.input_layernorm.weight', 'language_model.layers.24.laurel.linear_left.weight', 'language_model.layers.24.laurel.linear_right.weight', 'language_model.layers.24.laurel.post_laurel_norm.weight', 'language_model.layers.24.mlp.down_proj.weight', 'language_model.layers.24.mlp.gate_proj.weight', 'language_model.layers.24.mlp.up_proj.weight', 'language_model.layers.24.per_layer_input_gate.weight', 'language_model.layers.24.per_layer_projection.weight', 'language_model.layers.24.post_attention_layernorm.weight', 'language_model.layers.24.post_feedforward_layernorm.weight', 'language_model.layers.24.post_per_layer_input_norm.weight', 'language_model.layers.24.pre_feedforward_layernorm.weight', 'language_model.layers.24.self_attn.k_norm.weight', 'language_model.layers.24.self_attn.k_proj.weight', 'language_model.layers.24.self_attn.o_proj.weight', 'language_model.layers.24.self_attn.q_norm.weight', 'language_model.layers.24.self_attn.q_proj.weight', 'language_model.layers.24.self_attn.v_proj.weight', 'language_model.layers.25.altup.correct_output_scale', 'language_model.layers.25.altup.correction_coefs.weight', 'language_model.layers.25.altup.modality_router.weight', 'language_model.layers.25.altup.prediction_coefs.weight', 'language_model.layers.25.altup.router_norm.weight', 'language_model.layers.25.input_layernorm.weight', 'language_model.layers.25.laurel.linear_left.weight', 'language_model.layers.25.laurel.linear_right.weight', 'language_model.layers.25.laurel.post_laurel_norm.weight', 'language_model.layers.25.mlp.down_proj.weight', 'language_model.layers.25.mlp.gate_proj.weight', 'language_model.layers.25.mlp.up_proj.weight', 'language_model.layers.25.per_layer_input_gate.weight', 'language_model.layers.25.per_layer_projection.weight', 'language_model.layers.25.post_attention_layernorm.weight', 'language_model.layers.25.post_feedforward_layernorm.weight', 'language_model.layers.25.post_per_layer_input_norm.weight', 'language_model.layers.25.pre_feedforward_layernorm.weight', 'language_model.layers.25.self_attn.k_norm.weight', 'language_model.layers.25.self_attn.k_proj.weight', 'language_model.layers.25.self_attn.o_proj.weight', 'language_model.layers.25.self_attn.q_norm.weight', 'language_model.layers.25.self_attn.q_proj.weight', 'language_model.layers.25.self_attn.v_proj.weight', 'language_model.layers.26.altup.correct_output_scale', 'language_model.layers.26.altup.correction_coefs.weight', 'language_model.layers.26.altup.modality_router.weight', 'language_model.layers.26.altup.prediction_coefs.weight', 'language_model.layers.26.altup.router_norm.weight', 'language_model.layers.26.input_layernorm.weight', 'language_model.layers.26.laurel.linear_left.weight', 'language_model.layers.26.laurel.linear_right.weight', 'language_model.layers.26.laurel.post_laurel_norm.weight', 'language_model.layers.26.mlp.down_proj.weight', 'language_model.layers.26.mlp.gate_proj.weight', 'language_model.layers.26.mlp.up_proj.weight', 'language_model.layers.26.per_layer_input_gate.weight', 'language_model.layers.26.per_layer_projection.weight', 'language_model.layers.26.post_attention_layernorm.weight', 'language_model.layers.26.post_feedforward_layernorm.weight', 'language_model.layers.26.post_per_layer_input_norm.weight', 'language_model.layers.26.pre_feedforward_layernorm.weight', 'language_model.layers.26.self_attn.k_norm.weight', 'language_model.layers.26.self_attn.k_proj.weight', 'language_model.layers.26.self_attn.o_proj.weight', 'language_model.layers.26.self_attn.q_norm.weight', 'language_model.layers.26.self_attn.q_proj.weight', 'language_model.layers.26.self_attn.v_proj.weight', 'language_model.layers.27.altup.correct_output_scale', 'language_model.layers.27.altup.correction_coefs.weight', 'language_model.layers.27.altup.modality_router.weight', 'language_model.layers.27.altup.prediction_coefs.weight', 'language_model.layers.27.altup.router_norm.weight', 'language_model.layers.27.input_layernorm.weight', 'language_model.layers.27.laurel.linear_left.weight', 'language_model.layers.27.laurel.linear_right.weight', 'language_model.layers.27.laurel.post_laurel_norm.weight', 'language_model.layers.27.mlp.down_proj.weight', 'language_model.layers.27.mlp.gate_proj.weight', 'language_model.layers.27.mlp.up_proj.weight', 'language_model.layers.27.per_layer_input_gate.weight', 'language_model.layers.27.per_layer_projection.weight', 'language_model.layers.27.post_attention_layernorm.weight', 'language_model.layers.27.post_feedforward_layernorm.weight', 'language_model.layers.27.post_per_layer_input_norm.weight', 'language_model.layers.27.pre_feedforward_layernorm.weight', 'language_model.layers.27.self_attn.k_norm.weight', 'language_model.layers.27.self_attn.k_proj.weight', 'language_model.layers.27.self_attn.o_proj.weight', 'language_model.layers.27.self_attn.q_norm.weight', 'language_model.layers.27.self_attn.q_proj.weight', 'language_model.layers.27.self_attn.v_proj.weight', 'language_model.layers.28.altup.correct_output_scale', 'language_model.layers.28.altup.correction_coefs.weight', 'language_model.layers.28.altup.modality_router.weight', 'language_model.layers.28.altup.prediction_coefs.weight', 'language_model.layers.28.altup.router_norm.weight', 'language_model.layers.28.input_layernorm.weight', 'language_model.layers.28.laurel.linear_left.weight', 'language_model.layers.28.laurel.linear_right.weight', 'language_model.layers.28.laurel.post_laurel_norm.weight', 'language_model.layers.28.mlp.down_proj.weight', 'language_model.layers.28.mlp.gate_proj.weight', 'language_model.layers.28.mlp.up_proj.weight', 'language_model.layers.28.per_layer_input_gate.weight', 'language_model.layers.28.per_layer_projection.weight', 'language_model.layers.28.post_attention_layernorm.weight', 'language_model.layers.28.post_feedforward_layernorm.weight', 'language_model.layers.28.post_per_layer_input_norm.weight', 'language_model.layers.28.pre_feedforward_layernorm.weight', 'language_model.layers.28.self_attn.k_norm.weight', 'language_model.layers.28.self_attn.k_proj.weight', 'language_model.layers.28.self_attn.o_proj.weight', 'language_model.layers.28.self_attn.q_norm.weight', 'language_model.layers.28.self_attn.q_proj.weight', 'language_model.layers.28.self_attn.v_proj.weight', 'language_model.layers.29.altup.correct_output_scale', 'language_model.layers.29.altup.correction_coefs.weight', 'language_model.layers.29.altup.modality_router.weight', 'language_model.layers.29.altup.prediction_coefs.weight', 'language_model.layers.29.altup.router_norm.weight', 'language_model.layers.29.input_layernorm.weight', 'language_model.layers.29.laurel.linear_left.weight', 'language_model.layers.29.laurel.linear_right.weight', 'language_model.layers.29.laurel.post_laurel_norm.weight', 'language_model.layers.29.mlp.down_proj.weight', 'language_model.layers.29.mlp.gate_proj.weight', 'language_model.layers.29.mlp.up_proj.weight', 'language_model.layers.29.per_layer_input_gate.weight', 'language_model.layers.29.per_layer_projection.weight', 'language_model.layers.29.post_attention_layernorm.weight', 'language_model.layers.29.post_feedforward_layernorm.weight', 'language_model.layers.29.post_per_layer_input_norm.weight', 'language_model.layers.29.pre_feedforward_layernorm.weight', 'language_model.layers.29.self_attn.k_norm.weight', 'language_model.layers.29.self_attn.k_proj.weight', 'language_model.layers.29.self_attn.o_proj.weight', 'language_model.layers.29.self_attn.q_norm.weight', 'language_model.layers.29.self_attn.q_proj.weight', 'language_model.layers.29.self_attn.v_proj.weight', 'language_model.layers.3.altup.correct_output_scale', 'language_model.layers.3.altup.correction_coefs.weight', 'language_model.layers.3.altup.modality_router.weight', 'language_model.layers.3.altup.prediction_coefs.weight', 'language_model.layers.3.altup.router_norm.weight', 'language_model.layers.3.input_layernorm.weight', 'language_model.layers.3.laurel.linear_left.weight', 'language_model.layers.3.laurel.linear_right.weight', 'language_model.layers.3.laurel.post_laurel_norm.weight', 'language_model.layers.3.mlp.down_proj.weight', 'language_model.layers.3.mlp.gate_proj.weight', 'language_model.layers.3.mlp.up_proj.weight', 'language_model.layers.3.per_layer_input_gate.weight', 'language_model.layers.3.per_layer_projection.weight', 'language_model.layers.3.post_attention_layernorm.weight', 'language_model.layers.3.post_feedforward_layernorm.weight', 'language_model.layers.3.post_per_layer_input_norm.weight', 'language_model.layers.3.pre_feedforward_layernorm.weight', 'language_model.layers.3.self_attn.k_norm.weight', 'language_model.layers.3.self_attn.k_proj.weight', 'language_model.layers.3.self_attn.o_proj.weight', 'language_model.layers.3.self_attn.q_norm.weight', 'language_model.layers.3.self_attn.q_proj.weight', 'language_model.layers.3.self_attn.v_proj.weight', 'language_model.layers.4.altup.correct_output_scale', 'language_model.layers.4.altup.correction_coefs.weight', 'language_model.layers.4.altup.modality_router.weight', 'language_model.layers.4.altup.prediction_coefs.weight', 'language_model.layers.4.altup.router_norm.weight', 'language_model.layers.4.input_layernorm.weight', 'language_model.layers.4.laurel.linear_left.weight', 'language_model.layers.4.laurel.linear_right.weight', 'language_model.layers.4.laurel.post_laurel_norm.weight', 'language_model.layers.4.mlp.down_proj.weight', 'language_model.layers.4.mlp.gate_proj.weight', 'language_model.layers.4.mlp.up_proj.weight', 'language_model.layers.4.per_layer_input_gate.weight', 'language_model.layers.4.per_layer_projection.weight', 'language_model.layers.4.post_attention_layernorm.weight', 'language_model.layers.4.post_feedforward_layernorm.weight', 'language_model.layers.4.post_per_layer_input_norm.weight', 'language_model.layers.4.pre_feedforward_layernorm.weight', 'language_model.layers.4.self_attn.k_norm.weight', 'language_model.layers.4.self_attn.k_proj.weight', 'language_model.layers.4.self_attn.o_proj.weight', 'language_model.layers.4.self_attn.q_norm.weight', 'language_model.layers.4.self_attn.q_proj.weight', 'language_model.layers.4.self_attn.v_proj.weight', 'language_model.layers.5.altup.correct_output_scale', 'language_model.layers.5.altup.correction_coefs.weight', 'language_model.layers.5.altup.modality_router.weight', 'language_model.layers.5.altup.prediction_coefs.weight', 'language_model.layers.5.altup.router_norm.weight', 'language_model.layers.5.input_layernorm.weight', 'language_model.layers.5.laurel.linear_left.weight', 'language_model.layers.5.laurel.linear_right.weight', 'language_model.layers.5.laurel.post_laurel_norm.weight', 'language_model.layers.5.mlp.down_proj.weight', 'language_model.layers.5.mlp.gate_proj.weight', 'language_model.layers.5.mlp.up_proj.weight', 'language_model.layers.5.per_layer_input_gate.weight', 'language_model.layers.5.per_layer_projection.weight', 'language_model.layers.5.post_attention_layernorm.weight', 'language_model.layers.5.post_feedforward_layernorm.weight', 'language_model.layers.5.post_per_layer_input_norm.weight', 'language_model.layers.5.pre_feedforward_layernorm.weight', 'language_model.layers.5.self_attn.k_norm.weight', 'language_model.layers.5.self_attn.k_proj.weight', 'language_model.layers.5.self_attn.o_proj.weight', 'language_model.layers.5.self_attn.q_norm.weight', 'language_model.layers.5.self_attn.q_proj.weight', 'language_model.layers.5.self_attn.v_proj.weight', 'language_model.layers.6.altup.correct_output_scale', 'language_model.layers.6.altup.correction_coefs.weight', 'language_model.layers.6.altup.modality_router.weight', 'language_model.layers.6.altup.prediction_coefs.weight', 'language_model.layers.6.altup.router_norm.weight', 'language_model.layers.6.input_layernorm.weight', 'language_model.layers.6.laurel.linear_left.weight', 'language_model.layers.6.laurel.linear_right.weight', 'language_model.layers.6.laurel.post_laurel_norm.weight', 'language_model.layers.6.mlp.down_proj.weight', 'language_model.layers.6.mlp.gate_proj.weight', 'language_model.layers.6.mlp.up_proj.weight', 'language_model.layers.6.per_layer_input_gate.weight', 'language_model.layers.6.per_layer_projection.weight', 'language_model.layers.6.post_attention_layernorm.weight', 'language_model.layers.6.post_feedforward_layernorm.weight', 'language_model.layers.6.post_per_layer_input_norm.weight', 'language_model.layers.6.pre_feedforward_layernorm.weight', 'language_model.layers.6.self_attn.k_norm.weight', 'language_model.layers.6.self_attn.k_proj.weight', 'language_model.layers.6.self_attn.o_proj.weight', 'language_model.layers.6.self_attn.q_norm.weight', 'language_model.layers.6.self_attn.q_proj.weight', 'language_model.layers.6.self_attn.v_proj.weight', 'language_model.layers.7.altup.correct_output_scale', 'language_model.layers.7.altup.correction_coefs.weight', 'language_model.layers.7.altup.modality_router.weight', 'language_model.layers.7.altup.prediction_coefs.weight', 'language_model.layers.7.altup.router_norm.weight', 'language_model.layers.7.input_layernorm.weight', 'language_model.layers.7.laurel.linear_left.weight', 'language_model.layers.7.laurel.linear_right.weight', 'language_model.layers.7.laurel.post_laurel_norm.weight', 'language_model.layers.7.mlp.down_proj.weight', 'language_model.layers.7.mlp.gate_proj.weight', 'language_model.layers.7.mlp.up_proj.weight', 'language_model.layers.7.per_layer_input_gate.weight', 'language_model.layers.7.per_layer_projection.weight', 'language_model.layers.7.post_attention_layernorm.weight', 'language_model.layers.7.post_feedforward_layernorm.weight', 'language_model.layers.7.post_per_layer_input_norm.weight', 'language_model.layers.7.pre_feedforward_layernorm.weight', 'language_model.layers.7.self_attn.k_norm.weight', 'language_model.layers.7.self_attn.k_proj.weight', 'language_model.layers.7.self_attn.o_proj.weight', 'language_model.layers.7.self_attn.q_norm.weight', 'language_model.layers.7.self_attn.q_proj.weight', 'language_model.layers.7.self_attn.v_proj.weight', 'language_model.layers.8.altup.correct_output_scale', 'language_model.layers.8.altup.correction_coefs.weight', 'language_model.layers.8.altup.modality_router.weight', 'language_model.layers.8.altup.prediction_coefs.weight', 'language_model.layers.8.altup.router_norm.weight', 'language_model.layers.8.input_layernorm.weight', 'language_model.layers.8.laurel.linear_left.weight', 'language_model.layers.8.laurel.linear_right.weight', 'language_model.layers.8.laurel.post_laurel_norm.weight', 'language_model.layers.8.mlp.down_proj.weight', 'language_model.layers.8.mlp.gate_proj.weight', 'language_model.layers.8.mlp.up_proj.weight', 'language_model.layers.8.per_layer_input_gate.weight', 'language_model.layers.8.per_layer_projection.weight', 'language_model.layers.8.post_attention_layernorm.weight', 'language_model.layers.8.post_feedforward_layernorm.weight', 'language_model.layers.8.post_per_layer_input_norm.weight', 'language_model.layers.8.pre_feedforward_layernorm.weight', 'language_model.layers.8.self_attn.k_norm.weight', 'language_model.layers.8.self_attn.k_proj.weight', 'language_model.layers.8.self_attn.o_proj.weight', 'language_model.layers.8.self_attn.q_norm.weight', 'language_model.layers.8.self_attn.q_proj.weight', 'language_model.layers.8.self_attn.v_proj.weight', 'language_model.layers.9.altup.correct_output_scale', 'language_model.layers.9.altup.correction_coefs.weight', 'language_model.layers.9.altup.modality_router.weight', 'language_model.layers.9.altup.prediction_coefs.weight', 'language_model.layers.9.altup.router_norm.weight', 'language_model.layers.9.input_layernorm.weight', 'language_model.layers.9.laurel.linear_left.weight', 'language_model.layers.9.laurel.linear_right.weight', 'language_model.layers.9.laurel.post_laurel_norm.weight', 'language_model.layers.9.mlp.down_proj.weight', 'language_model.layers.9.mlp.gate_proj.weight', 'language_model.layers.9.mlp.up_proj.weight', 'language_model.layers.9.per_layer_input_gate.weight', 'language_model.layers.9.per_layer_projection.weight', 'language_model.layers.9.post_attention_layernorm.weight', 'language_model.layers.9.post_feedforward_layernorm.weight', 'language_model.layers.9.post_per_layer_input_norm.weight', 'language_model.layers.9.pre_feedforward_layernorm.weight', 'language_model.layers.9.self_attn.k_norm.weight', 'language_model.layers.9.self_attn.k_proj.weight', 'language_model.layers.9.self_attn.o_proj.weight', 'language_model.layers.9.self_attn.q_norm.weight', 'language_model.layers.9.self_attn.q_proj.weight', 'language_model.layers.9.self_attn.v_proj.weight', 'language_model.norm.weight', 'language_model.per_layer_model_projection.weight', 'language_model.per_layer_projection_norm.weight', 'vision_tower.timm_model.blocks.0.0.bn1.weight', 'vision_tower.timm_model.blocks.0.0.bn2.weight', 'vision_tower.timm_model.blocks.0.0.conv_exp.weight', 'vision_tower.timm_model.blocks.0.0.conv_pwl.weight', 'vision_tower.timm_model.blocks.0.1.bn1.weight', 'vision_tower.timm_model.blocks.0.1.bn2.weight', 'vision_tower.timm_model.blocks.0.1.conv_exp.weight', 'vision_tower.timm_model.blocks.0.1.conv_pwl.weight', 'vision_tower.timm_model.blocks.0.2.bn1.weight', 'vision_tower.timm_model.blocks.0.2.bn2.weight', 'vision_tower.timm_model.blocks.0.2.conv_exp.weight', 'vision_tower.timm_model.blocks.0.2.conv_pwl.weight', 'vision_tower.timm_model.blocks.1.0.dw_mid.bn.weight', 'vision_tower.timm_model.blocks.1.0.dw_mid.conv.weight', 'vision_tower.timm_model.blocks.1.0.dw_start.bn.weight', 'vision_tower.timm_model.blocks.1.0.dw_start.conv.weight', 'vision_tower.timm_model.blocks.1.0.layer_scale.gamma', 'vision_tower.timm_model.blocks.1.0.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.1.0.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.1.0.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.1.0.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.1.1.dw_start.bn.weight', 'vision_tower.timm_model.blocks.1.1.dw_start.conv.weight', 'vision_tower.timm_model.blocks.1.1.layer_scale.gamma', 'vision_tower.timm_model.blocks.1.1.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.1.1.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.1.1.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.1.1.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.1.2.dw_start.bn.weight', 'vision_tower.timm_model.blocks.1.2.dw_start.conv.weight', 'vision_tower.timm_model.blocks.1.2.layer_scale.gamma', 'vision_tower.timm_model.blocks.1.2.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.1.2.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.1.2.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.1.2.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.1.3.dw_start.bn.weight', 'vision_tower.timm_model.blocks.1.3.dw_start.conv.weight', 'vision_tower.timm_model.blocks.1.3.layer_scale.gamma', 'vision_tower.timm_model.blocks.1.3.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.1.3.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.1.3.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.1.3.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.1.4.dw_start.bn.weight', 'vision_tower.timm_model.blocks.1.4.dw_start.conv.weight', 'vision_tower.timm_model.blocks.1.4.layer_scale.gamma', 'vision_tower.timm_model.blocks.1.4.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.1.4.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.1.4.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.1.4.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.0.dw_mid.bn.weight', 'vision_tower.timm_model.blocks.2.0.dw_mid.conv.weight', 'vision_tower.timm_model.blocks.2.0.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.0.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.0.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.0.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.0.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.0.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.0.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.1.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.1.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.1.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.1.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.1.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.1.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.1.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.10.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.10.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.10.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.10.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.10.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.11.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.11.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.11.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.11.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.11.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.11.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.11.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.11.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.11.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.11.norm.weight', 'vision_tower.timm_model.blocks.2.12.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.12.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.12.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.12.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.12.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.13.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.13.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.13.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.13.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.13.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.13.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.13.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.13.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.13.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.13.norm.weight', 'vision_tower.timm_model.blocks.2.14.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.14.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.14.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.14.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.14.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.15.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.15.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.15.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.15.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.15.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.15.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.15.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.15.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.15.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.15.norm.weight', 'vision_tower.timm_model.blocks.2.16.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.16.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.16.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.16.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.16.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.17.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.17.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.17.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.17.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.17.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.17.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.17.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.17.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.17.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.17.norm.weight', 'vision_tower.timm_model.blocks.2.18.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.18.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.18.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.18.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.18.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.19.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.19.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.19.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.19.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.19.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.19.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.19.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.19.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.19.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.19.norm.weight', 'vision_tower.timm_model.blocks.2.2.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.2.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.2.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.2.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.2.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.2.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.2.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.20.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.20.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.20.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.20.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.20.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.21.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.21.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.21.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.21.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.21.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.21.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.21.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.21.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.21.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.21.norm.weight', 'vision_tower.timm_model.blocks.2.22.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.22.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.22.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.22.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.22.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.23.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.23.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.23.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.23.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.23.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.23.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.23.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.23.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.23.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.23.norm.weight', 'vision_tower.timm_model.blocks.2.24.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.24.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.24.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.24.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.24.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.25.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.25.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.25.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.25.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.25.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.25.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.25.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.25.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.25.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.25.norm.weight', 'vision_tower.timm_model.blocks.2.26.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.26.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.26.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.26.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.26.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.27.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.27.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.27.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.27.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.27.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.27.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.27.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.27.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.27.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.27.norm.weight', 'vision_tower.timm_model.blocks.2.28.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.28.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.28.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.28.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.28.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.29.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.29.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.29.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.29.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.29.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.29.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.29.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.29.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.29.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.29.norm.weight', 'vision_tower.timm_model.blocks.2.3.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.3.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.3.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.3.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.3.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.3.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.3.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.30.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.30.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.30.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.30.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.30.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.31.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.31.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.31.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.31.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.31.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.31.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.31.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.31.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.31.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.31.norm.weight', 'vision_tower.timm_model.blocks.2.32.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.32.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.32.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.32.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.32.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.33.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.33.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.33.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.33.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.33.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.33.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.33.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.33.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.33.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.33.norm.weight', 'vision_tower.timm_model.blocks.2.34.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.34.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.34.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.34.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.34.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.35.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.35.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.35.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.35.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.35.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.35.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.35.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.35.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.35.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.35.norm.weight', 'vision_tower.timm_model.blocks.2.36.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.36.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.36.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.36.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.36.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.4.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.4.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.4.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.4.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.4.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.4.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.4.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.5.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.5.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.5.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.5.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.5.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.5.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.5.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.6.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.6.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.6.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.6.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.6.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.6.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.6.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.7.dw_start.bn.weight', 'vision_tower.timm_model.blocks.2.7.dw_start.conv.weight', 'vision_tower.timm_model.blocks.2.7.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.7.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.7.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.7.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.7.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.8.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.8.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.2.8.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.2.8.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.2.8.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.2.9.attn.key.down_conv.weight', 'vision_tower.timm_model.blocks.2.9.attn.key.norm.weight', 'vision_tower.timm_model.blocks.2.9.attn.key.proj.weight', 'vision_tower.timm_model.blocks.2.9.attn.output.proj.weight', 'vision_tower.timm_model.blocks.2.9.attn.query.proj.weight', 'vision_tower.timm_model.blocks.2.9.attn.value.down_conv.weight', 'vision_tower.timm_model.blocks.2.9.attn.value.norm.weight', 'vision_tower.timm_model.blocks.2.9.attn.value.proj.weight', 'vision_tower.timm_model.blocks.2.9.layer_scale.gamma', 'vision_tower.timm_model.blocks.2.9.norm.weight', 'vision_tower.timm_model.blocks.3.0.dw_mid.bn.weight', 'vision_tower.timm_model.blocks.3.0.dw_mid.conv.weight', 'vision_tower.timm_model.blocks.3.0.dw_start.bn.weight', 'vision_tower.timm_model.blocks.3.0.dw_start.conv.weight', 'vision_tower.timm_model.blocks.3.0.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.0.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.0.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.0.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.0.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.1.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.1.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.1.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.1.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.1.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.1.norm.weight', 'vision_tower.timm_model.blocks.3.10.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.10.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.10.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.10.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.10.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.11.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.11.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.11.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.11.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.11.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.11.norm.weight', 'vision_tower.timm_model.blocks.3.12.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.12.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.12.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.12.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.12.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.13.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.13.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.13.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.13.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.13.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.13.norm.weight', 'vision_tower.timm_model.blocks.3.14.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.14.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.14.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.14.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.14.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.15.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.15.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.15.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.15.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.15.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.15.norm.weight', 'vision_tower.timm_model.blocks.3.16.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.16.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.16.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.16.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.16.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.17.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.17.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.17.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.17.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.17.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.17.norm.weight', 'vision_tower.timm_model.blocks.3.18.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.18.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.18.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.18.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.18.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.19.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.19.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.19.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.19.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.19.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.19.norm.weight', 'vision_tower.timm_model.blocks.3.2.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.2.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.2.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.2.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.2.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.20.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.20.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.20.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.20.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.20.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.21.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.21.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.21.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.21.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.21.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.21.norm.weight', 'vision_tower.timm_model.blocks.3.22.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.22.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.22.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.22.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.22.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.23.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.23.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.23.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.23.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.23.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.23.norm.weight', 'vision_tower.timm_model.blocks.3.24.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.24.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.24.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.24.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.24.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.25.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.25.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.25.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.25.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.25.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.25.norm.weight', 'vision_tower.timm_model.blocks.3.26.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.26.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.26.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.26.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.26.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.27.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.27.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.27.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.27.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.27.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.27.norm.weight', 'vision_tower.timm_model.blocks.3.28.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.28.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.28.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.28.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.28.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.29.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.29.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.29.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.29.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.29.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.29.norm.weight', 'vision_tower.timm_model.blocks.3.3.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.3.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.3.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.3.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.3.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.3.norm.weight', 'vision_tower.timm_model.blocks.3.30.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.30.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.30.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.30.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.30.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.31.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.31.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.31.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.31.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.31.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.31.norm.weight', 'vision_tower.timm_model.blocks.3.32.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.32.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.32.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.32.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.32.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.33.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.33.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.33.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.33.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.33.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.33.norm.weight', 'vision_tower.timm_model.blocks.3.34.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.34.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.34.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.34.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.34.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.35.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.35.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.35.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.35.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.35.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.35.norm.weight', 'vision_tower.timm_model.blocks.3.36.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.36.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.36.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.36.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.36.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.37.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.37.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.37.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.37.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.37.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.37.norm.weight', 'vision_tower.timm_model.blocks.3.38.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.38.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.38.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.38.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.38.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.4.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.4.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.4.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.4.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.4.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.5.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.5.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.5.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.5.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.5.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.5.norm.weight', 'vision_tower.timm_model.blocks.3.6.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.6.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.6.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.6.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.6.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.7.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.7.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.7.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.7.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.7.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.7.norm.weight', 'vision_tower.timm_model.blocks.3.8.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.8.pw_exp.bn.weight', 'vision_tower.timm_model.blocks.3.8.pw_exp.conv.weight', 'vision_tower.timm_model.blocks.3.8.pw_proj.bn.weight', 'vision_tower.timm_model.blocks.3.8.pw_proj.conv.weight', 'vision_tower.timm_model.blocks.3.9.attn.key.proj.weight', 'vision_tower.timm_model.blocks.3.9.attn.output.proj.weight', 'vision_tower.timm_model.blocks.3.9.attn.query.proj.weight', 'vision_tower.timm_model.blocks.3.9.attn.value.proj.weight', 'vision_tower.timm_model.blocks.3.9.layer_scale.gamma', 'vision_tower.timm_model.blocks.3.9.norm.weight', 'vision_tower.timm_model.conv_stem.bn.weight', 'vision_tower.timm_model.conv_stem.conv.bias', 'vision_tower.timm_model.conv_stem.conv.weight', 'vision_tower.timm_model.msfa.ffn.pw_exp.bn.weight', 'vision_tower.timm_model.msfa.ffn.pw_exp.conv.weight', 'vision_tower.timm_model.msfa.ffn.pw_proj.bn.weight', 'vision_tower.timm_model.msfa.ffn.pw_proj.conv.weight', 'vision_tower.timm_model.msfa.norm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Gemma3nModel' object has no attribute 'prepare_inputs_for_generation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# defer to nn.Module's logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'prepare_inputs_for_generation'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1393660976.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load base Gemma 3n model and LoRA adapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/gemma-3n-e2b-it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLORA_CHECKPOINT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Merge LoRA weights and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, key_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             )\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             model = MODEL_TYPE_TO_PEFT_MODEL_MAPPING[config.task_type](\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, peft_config, adapter_name, **kwargs)\u001b[0m\n\u001b[1;32m   1809\u001b[0m     ) -> None:\n\u001b[1;32m   1810\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prepare_inputs_for_generation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m     def forward(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/model.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# see #1892: prevent infinite recursion if class is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_peft_config_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Gemma3nModel' object has no attribute 'prepare_inputs_for_generation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert merged model\n",
        "config = converter.ConversionConfig(\n",
        "    input_ckpt=\"/tmp/merged_gemma3n\",\n",
        "    ckpt_format=\"pytorch\",\n",
        "    model_type=\"GEMMA_3N_IT\",\n",
        "    output_dir=OUTPUT_DIRECTORY,\n",
        "    backend=\"gpu\",\n",
        ")\n",
        "converter.convert(config)"
      ],
      "metadata": {
        "id": "4LhE0NJ1TwkH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e64fe85a4484c9fa9fee6267b33586f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3fdaa7aee9e438a8406c1e2fa452bf8",
              "IPY_MODEL_1991954fb22e46a2a7b0e2435b3a2fca",
              "IPY_MODEL_f0f576e046ec4f88b742066ca8cc9fbe"
            ],
            "layout": "IPY_MODEL_d365229bcf6f4c6eb868b10b293d74af"
          }
        },
        "b3fdaa7aee9e438a8406c1e2fa452bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3596de1d34a4052a1c5234e14f7803c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e991e8cdd0724da694f530c1dbcbe9ce",
            "value": "gemma-3n-E2B-it-int4.task:‚Äá100%"
          }
        },
        "1991954fb22e46a2a7b0e2435b3a2fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be309f64a7c24bb987da71c76ee01d7f",
            "max": 3136226711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f8696e08b08480d8e9402fb8a06e210",
            "value": 3136226711
          }
        },
        "f0f576e046ec4f88b742066ca8cc9fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2edd5919b6334633a2aaca4d099714b2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dec81946e25f47718fb678bea9704180",
            "value": "‚Äá3.14G/3.14G‚Äá[00:15&lt;00:00,‚Äá339MB/s]"
          }
        },
        "d365229bcf6f4c6eb868b10b293d74af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3596de1d34a4052a1c5234e14f7803c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e991e8cdd0724da694f530c1dbcbe9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be309f64a7c24bb987da71c76ee01d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8696e08b08480d8e9402fb8a06e210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2edd5919b6334633a2aaca4d099714b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec81946e25f47718fb678bea9704180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d0aacec1d494444bf6cbd5214008c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f58b91a8dcc54f5b88584edf687cf9d0",
              "IPY_MODEL_d3b64b893c0449a682ec48643b049846",
              "IPY_MODEL_755ed2a99e0347308bb024dc15c6f7af"
            ],
            "layout": "IPY_MODEL_b7aeb421b8f04eeda5b426446fc19410"
          }
        },
        "f58b91a8dcc54f5b88584edf687cf9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24ca5c245cf143d4adb1d09c7161bd1c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_db532df468524e0388bd5739d3fa6f13",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d3b64b893c0449a682ec48643b049846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb4f95cd47e46aebf8051236fb7d09c",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20d2b3cd4ff34348b58de61c8f1969db",
            "value": 3
          }
        },
        "755ed2a99e0347308bb024dc15c6f7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ea19090e0f542fda48b8021c11b989a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1b0ff2716ee748be8116762499616c83",
            "value": "‚Äá3/3‚Äá[00:00&lt;00:00,‚Äá‚Äá6.67it/s]"
          }
        },
        "b7aeb421b8f04eeda5b426446fc19410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ca5c245cf143d4adb1d09c7161bd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db532df468524e0388bd5739d3fa6f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb4f95cd47e46aebf8051236fb7d09c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d2b3cd4ff34348b58de61c8f1969db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ea19090e0f542fda48b8021c11b989a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0ff2716ee748be8116762499616c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}